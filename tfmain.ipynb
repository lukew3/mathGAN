{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KubxTY1mdiDm"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Reshape, Dropout, Dense \n",
    "from tensorflow.keras.layers import Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os \n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_list = [' ',\n",
    "             '1',\n",
    "             '2',\n",
    "             '3',\n",
    "             '4',\n",
    "             '5',\n",
    "             '6',\n",
    "             '7',\n",
    "             '8',\n",
    "             '9',\n",
    "             '0',\n",
    "             '+',\n",
    "             '-',\n",
    "             '*',\n",
    "             '/',\n",
    "             '=',\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_LIST_LEN = len(translate_list)\n",
    "PROBLEM_LENGTH = 20\n",
    "PROBLEM_DIM = PROBLEM_LENGTH * CHAR_LIST_LEN\n",
    "\n",
    "SEED_SIZE = 100\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prob_to_array(in_string):\n",
    "    problem_array = []\n",
    "    for char in in_string:\n",
    "        value = translate_list.index(char)\n",
    "        char_array = [0]*len(translate_list)\n",
    "        char_array[value] = 1\n",
    "        problem_array.append(char_array)\n",
    "    if len(in_string) < PROBLEM_LENGTH:\n",
    "        for _ in range(PROBLEM_LENGTH-len(in_string)):\n",
    "            char_array = [0]*len(translate_list)\n",
    "            char_array[0] = 1\n",
    "            problem_array.append(char_array)\n",
    "    return problem_array\n",
    "\n",
    "def array_to_prob(problem_array):\n",
    "    problem_string = \"\"\n",
    "    for char_array in problem_array:\n",
    "        largest = max(char_array)\n",
    "        value = char_array.index(largest)\n",
    "        char = translate_list[value]\n",
    "        problem_string += char\n",
    "    problem_string.strip()\n",
    "    return problem_string\n",
    "\n",
    "\n",
    "#myarr = prob_to_array('90+21')\n",
    "#myprob = array_to_prob(myarr)\n",
    "#print(myarr)\n",
    "#print(myprob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_input(count):\n",
    "    output_list = []\n",
    "    for _ in range(count):\n",
    "        left = random.randint(1,99)\n",
    "        right = random.randint(1,99)\n",
    "        problem = str(left) + '+' + str(right)\n",
    "        output_list.append(problem)\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_problems = generate_input(100)\n",
    "# print(input_problems)\n",
    "training_data = []\n",
    "for item in input_problems:\n",
    "    temp_arr = prob_to_array(item)\n",
    "    training_data.append(temp_arr)\n",
    "training_data = np.asarray(training_data)\n",
    "training_data = training_data.astype(np.float32)\n",
    "# print(\"Shape: \" + str(training_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(training_data) \\\n",
    "    .shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(seed_size, channels):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(4*4*256,activation=\"relu\",input_dim=seed_size))\n",
    "    model.add(Reshape((4,4,256)))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "   \n",
    "    # Output resolution, additional upsampling\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    if GENERATE_RES>1:\n",
    "      model.add(UpSampling2D(size=(GENERATE_RES,GENERATE_RES)))\n",
    "      model.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n",
    "      model.add(BatchNormalization(momentum=0.8))\n",
    "      model.add(Activation(\"relu\"))\n",
    "\n",
    "    # Final CNN layer\n",
    "    model.add(Conv2D(channels,kernel_size=3,padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_discriminator(image_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=image_shape, \n",
    "                     padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "t81_558_class_07_2_Keras_gan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
