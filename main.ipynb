{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "planned-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "distinguished-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dimension of problem, length of string\n",
    "\n",
    "char_list = [' ',\n",
    "             '1',\n",
    "             '2',\n",
    "             '3',\n",
    "             '4',\n",
    "             '5',\n",
    "             '6',\n",
    "             '7',\n",
    "             '8',\n",
    "             '9',\n",
    "             '0',\n",
    "             '+',\n",
    "             '-',\n",
    "             '*',\n",
    "             '/',\n",
    "             '=',\n",
    "            ]\n",
    "string_length = 20\n",
    "problem_dim = string_length * len(char_list)\n",
    "\n",
    "def problem_to_tensor(problem_string):\n",
    "    alphabet_size = len(char_list)\n",
    "    outlist = []\n",
    "    for char in problem_string:\n",
    "        # print(char)\n",
    "        inner_list = [0.] * alphabet_size\n",
    "        inner_list[char_list.index(char)] = 1.\n",
    "        # print(inner_list)\n",
    "        outlist.append(inner_list)\n",
    "    for _ in range(0, problem_dim-len(outlist)):\n",
    "        inner_list = [0.] * alphabet_size\n",
    "        outlist.append(inner_list)\n",
    "    # print(\"-----\")\n",
    "    t = torch.as_tensor(outlist)\n",
    "    return t\n",
    "\n",
    "def tensor_to_problem(t):\n",
    "    inlist = t.tolist()\n",
    "    #print(inlist)\n",
    "    outstring = \"\"\n",
    "    for sublist in inlist:\n",
    "        # print(len(sublist))\n",
    "        index = sublist.index(max(sublist))\n",
    "        print(\"INDEX: \" + str(index))\n",
    "        character = char_list[index]\n",
    "        print(character)\n",
    "        outstring += character\n",
    "    outstring = outstring.strip()\n",
    "    return outstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tamil-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, problem_dim):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            # Takes 20 digits as in_features\n",
    "            # Can the 20 be replaced with problem_dim?\n",
    "            nn.Linear(problem_dim, 5),\n",
    "            #Activation function\n",
    "            nn.LeakyReLU(0.01),\n",
    "            # One output node, 0 for fake, 1 for real\n",
    "            nn.Linear(5, 1),\n",
    "            # Makes sure that the node has a value between 0 and 1\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    # z_dim is the dimenion of the noise\n",
    "    # problem_dim is the dimension of the output (length of string)\n",
    "    def __init__(self, z_dim, problem_dim):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            # I think that 256 is just random to expand the noise\n",
    "            # 256 = 64*4\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(256, problem_dim),\n",
    "            # normalize inputs to [-1, 1] so make outputs [-1, 1]\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "scenic-volume",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters etc.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#learning rate ( play around with this if you want)\n",
    "lr = 3e-4\n",
    "# noise dimension (play with this as well)\n",
    "z_dim = 64 #try 128, 256\n",
    "batch_size = 1\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "discrete-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProblemDataset(Dataset):\n",
    "    def __init__(self, problem_list, transform=None):\n",
    "        self.problem_list = problem_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.problem_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        problem_string = self.problem_list[index]\n",
    "        problem_tensor = problem_to_tensor(problem_string)\n",
    "\n",
    "        return problem_tensor\n",
    "\n",
    "input_problems = ['32+90', '24+13', '93+03', '17+18', '68+03', '22+11', '50+50', '47+93', '08+29', '73+12']\n",
    "dataset = ProblemDataset(problem_list = input_problems)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "devoted-papua",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50] Batch 0/10                       Loss D: 0.7059, loss G: 0.8672\n",
      "tensor([[ 0.0298,  0.0288, -0.0741,  0.0470,  0.2929,  0.2282, -0.3234,  0.1663,\n",
      "          0.2079,  0.4134,  0.1176, -0.1425, -0.1584,  0.2428, -0.1657, -0.3612,\n",
      "          0.0925, -0.4082, -0.1295,  0.1531,  0.0453, -0.0188,  0.2590, -0.3797,\n",
      "          0.0250, -0.3265, -0.4409,  0.0010,  0.2621,  0.6340, -0.0427, -0.0749,\n",
      "          0.2051, -0.1463, -0.4045, -0.1516,  0.0339, -0.2773,  0.1634,  0.0007,\n",
      "         -0.2182, -0.2131,  0.3425,  0.1924,  0.4764, -0.0043,  0.2807,  0.2621,\n",
      "          0.0229,  0.3686,  0.1665,  0.3682, -0.3005,  0.0124, -0.0571,  0.0924,\n",
      "          0.1118, -0.2264, -0.0312,  0.2957,  0.1166,  0.0632, -0.2124, -0.2977,\n",
      "          0.0304, -0.1189, -0.0542,  0.2433,  0.3575, -0.2590,  0.2286, -0.1494,\n",
      "         -0.3733,  0.0657, -0.2001, -0.0276, -0.0647, -0.2159, -0.3026, -0.1243,\n",
      "          0.1497,  0.0326,  0.1448,  0.3787, -0.1209, -0.5516,  0.0863, -0.1402,\n",
      "         -0.2343,  0.2403, -0.0526,  0.1780, -0.0818,  0.2494,  0.0352,  0.1837,\n",
      "          0.2286,  0.1174,  0.2604, -0.3516, -0.0507, -0.0341,  0.2237, -0.0825,\n",
      "         -0.0587, -0.2263,  0.0365, -0.2831, -0.0834,  0.1012, -0.3044, -0.4868,\n",
      "          0.0442,  0.1992, -0.0976, -0.4299, -0.4907, -0.1271,  0.1844,  0.5246,\n",
      "          0.0972,  0.1883,  0.1191, -0.0436,  0.0113,  0.1663, -0.3403, -0.3710,\n",
      "          0.2349,  0.1896, -0.1697,  0.1503,  0.2886, -0.1698,  0.3849,  0.1150,\n",
      "         -0.0787, -0.2859, -0.0208,  0.3403, -0.1159,  0.1453, -0.3563,  0.0159,\n",
      "         -0.1695, -0.3386, -0.4165,  0.4334,  0.3342, -0.1417,  0.0212, -0.3455,\n",
      "          0.0881,  0.0261,  0.2113,  0.3053, -0.1500,  0.2284,  0.0596,  0.0694,\n",
      "         -0.2682, -0.5172,  0.2313, -0.0110, -0.3851,  0.0148, -0.0611, -0.0782,\n",
      "          0.0892,  0.1360,  0.2510,  0.0894, -0.0869, -0.3880, -0.0429, -0.0461,\n",
      "          0.1856, -0.4602,  0.2179,  0.1080, -0.3253,  0.2673, -0.2023, -0.2364,\n",
      "         -0.0488, -0.1628, -0.1865, -0.2965, -0.4917,  0.0564,  0.1348,  0.0260,\n",
      "          0.1615,  0.1553, -0.0642,  0.0179,  0.2257,  0.3607,  0.1413,  0.1439,\n",
      "         -0.3570,  0.2463,  0.1414, -0.2320,  0.1349,  0.2080,  0.1184, -0.1363,\n",
      "          0.1693, -0.2176,  0.1616, -0.0152,  0.2730,  0.1064,  0.1514,  0.0344,\n",
      "          0.1472, -0.1801,  0.1827,  0.3551,  0.1070, -0.2877,  0.2255,  0.1443,\n",
      "          0.1647, -0.4222, -0.1918,  0.0455, -0.1215, -0.3931, -0.0981, -0.0244,\n",
      "         -0.1327,  0.2661, -0.0444,  0.0462,  0.3661, -0.1490, -0.0580,  0.2313,\n",
      "         -0.1744, -0.0219,  0.2953, -0.2868,  0.1354,  0.3279,  0.0525, -0.1982,\n",
      "         -0.0545, -0.2192, -0.1898,  0.1109, -0.2011, -0.1051,  0.0171,  0.0586,\n",
      "         -0.3505, -0.2546,  0.0553, -0.1271,  0.2393, -0.0793, -0.2144,  0.1189,\n",
      "         -0.2060, -0.0059, -0.1336,  0.3966, -0.0338,  0.2872,  0.1559, -0.0609,\n",
      "          0.0211, -0.1518,  0.0345, -0.0050, -0.0194,  0.2572, -0.0054, -0.0098,\n",
      "         -0.1808,  0.2487, -0.3003,  0.0022,  0.1284,  0.4630, -0.2615,  0.0520,\n",
      "         -0.0430, -0.4025,  0.3569, -0.4185, -0.1867, -0.1322,  0.2366,  0.3136,\n",
      "         -0.3899, -0.1742, -0.0191, -0.0966, -0.3071, -0.1273,  0.0724,  0.2571,\n",
      "         -0.0481,  0.1205, -0.0252,  0.2035,  0.0545, -0.3379, -0.3354, -0.1256,\n",
      "         -0.1088, -0.0367,  0.3520, -0.0514, -0.3046, -0.2099,  0.1228, -0.2704]])\n",
      "tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "INDEX: 29\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-96d8380af234>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GENERATED \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtensor_to_problem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0;31m# print(\"--Output--------\" + str(tensor_to_problem(data)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-2d8c4fc2f583>\u001b[0m in \u001b[0;36mtensor_to_problem\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msublist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msublist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"INDEX: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mcharacter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcharacter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0moutstring\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcharacter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "disc = Discriminator(problem_dim).to(device)\n",
    "gen = Generator(z_dim, problem_dim).to(device)\n",
    "fixed_noise = torch.randn((batch_size, z_dim)).to(device)\n",
    "# Params of Normalize are mean and standard deviation of dataset\n",
    "transforms = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)),]\n",
    ")\n",
    "\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lr)\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "step = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, real in enumerate(loader):\n",
    "        # Keep current batch number, flatten real to size of 20\n",
    "        real = real.view(-1, problem_dim).to(device)\n",
    "        batch_size = real.shape[0]\n",
    "\n",
    "        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "        noise = torch.randn(batch_size, z_dim).to(device)\n",
    "        fake = gen(noise)\n",
    "        disc_real = disc(real).view(-1)\n",
    "        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        disc_fake = disc(fake).view(-1)\n",
    "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        lossD = (lossD_real + lossD_fake) / 2\n",
    "        disc.zero_grad()\n",
    "        lossD.backward(retain_graph=True)\n",
    "        opt_disc.step()\n",
    "\n",
    "        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "        # where the second option of maximizing doesn't suffer from\n",
    "        # saturating gradients\n",
    "        output = disc(fake).view(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} \\\n",
    "                      Loss D: {lossD:.4f}, loss G: {lossG:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise).reshape(-1, problem_dim)\n",
    "                # I think that data is the problem that the model was trained on\n",
    "                data = real.reshape(-1, problem_dim)\n",
    "                fake = nn.Unflatten('fake', )\n",
    "                print(fake)\n",
    "                print(data)\n",
    "                print(\"GENERATED \" + tensor_to_problem(fake))\n",
    "                # print(\"--Output--------\" + str(tensor_to_problem(data)))\n",
    "                \n",
    "                \n",
    "                #print(fake)\n",
    "                #print(data)\n",
    "                step += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-stylus",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
